{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Deep Feedforward Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. []()\n",
    "3.\n",
    "4.\n",
    "5.\n",
    "6. [References](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Introduction and gradient based learning <a id = \"intro\"></a>\n",
    "\n",
    "#### 2.1.1 Synthesis\n",
    "\n",
    "* They aim to approximate a function\n",
    "* Raw input values get translated into features in the hidden layers, such that in th eoutput layer, the function is lineary solvable\n",
    "* There is no feedback in the case of feedforward networks\n",
    "* Gradient based learning - Loss unfctions become nonconvex, meaning that gradient based optimizers just drive the value of the loss function a low value (local optima), as opposed to looking for global optima\n",
    "* Important to initialize weights to small random values, and biases to 0 or small positive values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Experiments\n",
    "\n",
    "##### 2.1.2.1 Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4fb019ac428a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The XOR function returns 1 when EXACTLY one of the inputs is 1\n",
    "* We need the hidden layer as the XOR function cannot be represented as direct linear transformation of the inputs\n",
    "\n",
    "![Why XOR cannot be represented as a linear function](XOR_Linear_Problem.png)\n",
    "\n",
    "* This is because, when x1 = 0, model's output must *increase* as x2 increases. However, when x1 = 1, the models ouput must *decrease* as x2 increases. A linear mode must also apply a fixed coefficient w2 on x2. This becomes impossible\n",
    "* Instead, in the learned feature space, we map the two inputs \\[0,1\\] and \\[1,0\\] to same point in the learned feature space (h). h = \\[0,1\\]\n",
    "* The linear model can now be applied on this - increasing in h1 and decreasing in h2\n",
    "\n",
    "![A simple network to solve the XOR problem](XOR_network.png)\n",
    "\n",
    "\n",
    "**First layer**\n",
    "The first layer is the input layer, which takes in the 4 possible inputs of diemension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First input layer\n",
    "X = tf.placeholder(tf.float32, shape = [4,2], name = 'X')\n",
    "\n",
    "# Actuals\n",
    "\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1], name = 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second layer**\n",
    "* The second layer contains the hidden units, which compute an affine transformation on the raw inputs\n",
    "* An affine transformation basically performs a linear transformation and adds an intercept, h = xT \\* W + c, where t and b are the parameters to be learnt\n",
    "* W is a square matrix, which performs a linear transformation on X\n",
    "* W will have n = 2, and hence m = 2\n",
    "* c will be a column vector of length of length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([2,2]), name = 'W')\n",
    "c = tf.Variable(tf.truncated_normal([4,2]), name = 'c')\n",
    "\n",
    "wt = tf.Variable(tf.zeros([2,1]), name = 'w')\n",
    "b = tf.Variable(tf.zeros([4,1]), name = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the layers\n",
    "\n",
    "with tf.name_scope(\"hidden_layer\") as scope:\n",
    "    h = tf.nn.relu(tf.add(tf.matmul(X,W), c))\n",
    "    \n",
    "with tf.name_scope(\"output\") as scope:\n",
    "    y_estimated = tf.sigmoid(tf.add(tf.matmul(h, wt), b))\n",
    "    \n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    loss = tf.reduce_mean(tf.squared_difference(y_estimated, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Epoch:  0\n",
      "   y_estimated: \n",
      "     [0.49983603]\n",
      "     [0.5001549]\n",
      "     [0.5001562]\n",
      "     [0.49984103]\n",
      "   W: \n",
      "     [ 0.06276221 -1.0465262 ]\n",
      "     [-1.9994133   0.46935537]\n",
      "   c: \n",
      "     [ 0.22249052 -0.17276908]\n",
      "     [-0.1103125  -0.37792176]\n",
      "     [-1.8173399  0.6337322]\n",
      "     [-0.23770733  0.762648  ]\n",
      "   w: \n",
      "     [-0.00013906]\n",
      "     [-5.87772e-05]\n",
      "   b \n",
      "     [-0.000625]\n",
      "     [0.000625]\n",
      "     [0.000625]\n",
      "     [-0.000625]\n",
      "   loss:  0.24984151\n",
      "________________________________________________________________________________\n",
      "Epoch:  10000\n",
      "   y_estimated: \n",
      "     [0.10032695]\n",
      "     [0.87701094]\n",
      "     [0.87692654]\n",
      "     [0.09273354]\n",
      "   W: \n",
      "     [ 0.06276221 -0.74257016]\n",
      "     [-1.9994133  0.5756058]\n",
      "   c: \n",
      "     [ 0.6710684  -0.17276908]\n",
      "     [-0.1103125  -0.57562596]\n",
      "     [-1.8173399  0.6337322]\n",
      "     [-0.23770733  1.0666034 ]\n",
      "   w: \n",
      "     [-0.6331325]\n",
      "     [-0.55834955]\n",
      "   b \n",
      "     [-1.7687219]\n",
      "     [1.9644246]\n",
      "     [1.9636419]\n",
      "     [-1.7783928]\n",
      "   loss:  0.012234598\n",
      "________________________________________________________________________________\n",
      "Epoch:  20000\n",
      "   y_estimated: \n",
      "     [0.05913892]\n",
      "     [0.9176089]\n",
      "     [0.91758096]\n",
      "     [0.04962243]\n",
      "   W: \n",
      "     [ 0.06276221 -0.6183995 ]\n",
      "     [-1.9994133   0.64538085]\n",
      "   c: \n",
      "     [ 0.8682611  -0.17276908]\n",
      "     [-0.1103125 -0.6453845]\n",
      "     [-1.8173399   0.61836934]\n",
      "     [-0.23770733  1.2061361 ]\n",
      "   w: \n",
      "     [-0.839286]\n",
      "     [-0.781674]\n",
      "   b \n",
      "     [-2.0381868]\n",
      "     [2.410293]\n",
      "     [2.409924]\n",
      "     [-1.9885205]\n",
      "   loss:  0.0048852465\n",
      "________________________________________________________________________________\n",
      "Epoch:  30000\n",
      "   y_estimated: \n",
      "     [0.04356773]\n",
      "     [0.93452203]\n",
      "     [0.93450755]\n",
      "     [0.03567083]\n",
      "   W: \n",
      "     [ 0.06276221 -0.58322793]\n",
      "     [-1.9994133  0.6805462]\n",
      "   c: \n",
      "     [ 0.97688204 -0.17276908]\n",
      "     [-0.1103125  -0.68054694]\n",
      "     [-1.8173399  0.5832127]\n",
      "     [-0.23770733  1.2764621 ]\n",
      "   w: \n",
      "     [-0.9512214]\n",
      "     [-0.89126474]\n",
      "   b \n",
      "     [-2.159662]\n",
      "     [2.658322]\n",
      "     [2.6580849]\n",
      "     [-2.0726974]\n",
      "   loss:  0.0029367954\n",
      "________________________________________________________________________________\n",
      "Epoch:  40000\n",
      "   y_estimated: \n",
      "     [0.0352436]\n",
      "     [0.9442343]\n",
      "     [0.9442251]\n",
      "     [0.02850174]\n",
      "   W: \n",
      "     [ 0.06276221 -0.56053704]\n",
      "     [-1.9994133   0.70322895]\n",
      "   c: \n",
      "     [ 1.0495082  -0.17276908]\n",
      "     [-0.1103125  -0.70324385]\n",
      "     [-1.8173399  0.5605235]\n",
      "     [-0.23770733  1.3218398 ]\n",
      "   w: \n",
      "     [-1.0256546]\n",
      "     [-0.9608069]\n",
      "   b \n",
      "     [-2.233159]\n",
      "     [2.8292158]\n",
      "     [2.8290405]\n",
      "     [-2.1217422]\n",
      "   loss:  0.0020687787\n",
      "________________________________________________________________________________\n",
      "Epoch:  50000\n",
      "   y_estimated: \n",
      "     [0.02999396]\n",
      "     [0.9506961]\n",
      "     [0.9506898]\n",
      "     [0.0240865]\n",
      "   W: \n",
      "     [ 0.06276221 -0.5441058 ]\n",
      "     [-1.9994133  0.7196645]\n",
      "   c: \n",
      "     [ 1.1032325  -0.17276908]\n",
      "     [-0.1103125  -0.71967053]\n",
      "     [-1.8173399  0.5440922]\n",
      "     [-0.23770733  1.3546989 ]\n",
      "   w: \n",
      "     [-1.0805665]\n",
      "     [-1.0107332]\n",
      "   b \n",
      "     [-2.2841904]\n",
      "     [2.959192]\n",
      "     [2.9590561]\n",
      "     [-2.1550403]\n",
      "   loss:  0.0015855418\n",
      "________________________________________________________________________________\n",
      "Epoch:  60000\n",
      "   y_estimated: \n",
      "     [0.02634794]\n",
      "     [0.9553766]\n",
      "     [0.95537174]\n",
      "     [0.02106446]\n",
      "   W: \n",
      "     [ 0.06276221 -0.53135043]\n",
      "     [-1.9994133   0.73241204]\n",
      "   c: \n",
      "     [ 1.1454744  -0.17276908]\n",
      "     [-0.1103125 -0.7324186]\n",
      "     [-1.8173399   0.53135204]\n",
      "     [-0.23770733  1.3801903 ]\n",
      "   w: \n",
      "     [-1.1236845]\n",
      "     [-1.0492345]\n",
      "   b \n",
      "     [-2.3225121]\n",
      "     [3.063848]\n",
      "     [3.0637343]\n",
      "     [-2.1797745]\n",
      "   loss:  0.0012802132\n",
      "________________________________________________________________________________\n",
      "Epoch:  70000\n",
      "   y_estimated: \n",
      "     [0.02364612]\n",
      "     [0.9589633]\n",
      "     [0.95895946]\n",
      "     [0.01884861]\n",
      "   W: \n",
      "     [ 0.06276221 -0.5210113 ]\n",
      "     [-1.9994133  0.7427623]\n",
      "   c: \n",
      "     [ 1.1801246  -0.17276908]\n",
      "     [-0.1103125 -0.7427639]\n",
      "     [-1.8173399  0.5209958]\n",
      "     [-0.23770733  1.4008827 ]\n",
      "   w: \n",
      "     [-1.15894]\n",
      "     [-1.0803651]\n",
      "   b \n",
      "     [-2.3529322]\n",
      "     [3.1513853]\n",
      "     [3.1512885]\n",
      "     [-2.1992507]\n",
      "   loss:  0.0010706871\n",
      "________________________________________________________________________________\n",
      "Epoch:  80000\n",
      "   y_estimated: \n",
      "     [0.02155499]\n",
      "     [0.9618227]\n",
      "     [0.96181977]\n",
      "     [0.01714787]\n",
      "   W: \n",
      "     [ 0.06276221 -0.5123448 ]\n",
      "     [-1.9994133   0.75142163]\n",
      "   c: \n",
      "     [ 1.2093294  -0.17276908]\n",
      "     [-0.1103125 -0.7514309]\n",
      "     [-1.8173399  0.5123357]\n",
      "     [-0.23770733  1.4182495 ]\n",
      "   w: \n",
      "     [-1.1886749]\n",
      "     [-1.1063496]\n",
      "   b \n",
      "     [-2.377858]\n",
      "     [3.22659]\n",
      "     [3.2265074]\n",
      "     [-2.2150028]\n",
      "   loss:  0.000918476\n",
      "________________________________________________________________________________\n",
      "Epoch:  90000\n",
      "   y_estimated: \n",
      "     [0.01988455]\n",
      "     [0.9641657]\n",
      "     [0.9641631]\n",
      "     [0.0157917]\n",
      "   W: \n",
      "     [ 0.06276221 -0.5049095 ]\n",
      "     [-1.9994133   0.75885797]\n",
      "   c: \n",
      "     [ 1.2345166  -0.17276908]\n",
      "     [-0.1103125 -0.758864 ]\n",
      "     [-1.8173399  0.5049016]\n",
      "     [-0.23770733  1.4331167 ]\n",
      "   w: \n",
      "     [-1.2142969]\n",
      "     [-1.1286223]\n",
      "   b \n",
      "     [-2.3986576]\n",
      "     [3.2923594]\n",
      "     [3.2922854]\n",
      "     [-2.2282934]\n",
      "   loss:  0.0008032882\n",
      "________________________________________________________________________________\n",
      "Epoch:  100000\n",
      "   y_estimated: \n",
      "     [0.01850833]\n",
      "     [0.9661343]\n",
      "     [0.9661321]\n",
      "     [0.01467907]\n",
      "   W: \n",
      "     [ 0.06276221 -0.498415  ]\n",
      "     [-1.9994133   0.76536167]\n",
      "   c: \n",
      "     [ 1.2566532  -0.17276908]\n",
      "     [-0.1103125 -0.765362 ]\n",
      "     [-1.8173399  0.4984158]\n",
      "     [-0.23770733  1.4460588 ]\n",
      "   w: \n",
      "     [-1.2367774]\n",
      "     [-1.1479946]\n",
      "   b \n",
      "     [-2.4166522]\n",
      "     [3.3509007]\n",
      "     [3.350835]\n",
      "     [-2.240024]\n",
      "   loss:  0.0007129882\n",
      "________________________________________________________________________________\n",
      "Elapsed time  106.610006\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "INPUT_XOR = [[0,0],[0,1],[1,0],[1,1]]\n",
    "OUTPUT_XOR = [[0],[1],[1],[0]]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs\", sess.graph)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "t_start = time.clock()\n",
    "for epoch in range(100001):\n",
    "    sess.run(train_step, feed_dict={X: INPUT_XOR, Y: OUTPUT_XOR})\n",
    "    if epoch % 10000 == 0:\n",
    "        print(\"_\"*80)\n",
    "        print('Epoch: ', epoch)\n",
    "        print('   y_estimated: ')\n",
    "        for element in sess.run(y_estimated, feed_dict={X: INPUT_XOR, Y: OUTPUT_XOR}):\n",
    "            print('    ',element)\n",
    "        print('   W: ')\n",
    "        for element in sess.run(W):\n",
    "            print('    ',element)\n",
    "        print('   c: ')\n",
    "        for element in sess.run(c):\n",
    "            print('    ',element)\n",
    "        print('   w: ')\n",
    "        for element in sess.run(wt):\n",
    "            print('    ',element)\n",
    "        print('   b ')\n",
    "        for element in sess.run(b):\n",
    "            print('    ',element)\n",
    "        print('   loss: ', sess.run(loss, feed_dict={X: INPUT_XOR, Y: OUTPUT_XOR}))\n",
    "t_end = time.clock()\n",
    "print(\"_\"*80)\n",
    "print('Elapsed time ', t_end - t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id = \"ref\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
